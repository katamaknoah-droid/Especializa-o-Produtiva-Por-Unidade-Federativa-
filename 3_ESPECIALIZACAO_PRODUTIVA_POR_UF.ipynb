{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e49e57cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas detectadas (mapa): {'CO_ANO': 'CO_ANO', 'SG_UF_NCM': 'SG_UF_MUN', 'CO_SH4': 'SH4', 'VL_FOB': 'VL_FOB', 'KG_LIQUIDO': 'KG_LIQUIDO', 'CO_URF': None}\n",
      "Top UFs FOB: ['SP', 'RJ', 'MG', 'PR', 'PA']\n",
      "Top UFs KG: ['PA', 'MG', 'RJ', 'SP', 'MT']\n",
      "Top 2 UFs por KG: ['PA', 'MG']\n",
      "CSV unificado salvo em: C:\\Users\\noahs\\Área de Trabalho\\DATASET NOAH_KATAMAK\\ANALISE_ARTIGO 02\\OUTPUT_DETALHADO\\unified_selected_rows_2018_2025.csv\n",
      "Excel salvo em: C:\\Users\\noahs\\Área de Trabalho\\DATASET NOAH_KATAMAK\\ANALISE_ARTIGO 02\\OUTPUT_DETALHADO\\analise_2018_2025_top5_por_uf_e_ufs_urf.xlsx\n",
      "Plots salvos em: C:\\Users\\noahs\\Área de Trabalho\\DATASET NOAH_KATAMAK\\ANALISE_ARTIGO 02\\OUTPUT_DETALHADO\\plots\n",
      "Processo concluído: 2025-10-10 11:32:57.556901\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CONFIG\n",
    "INPUT_CSV = r\"C:\\Users\\noahs\\Área de Trabalho\\DATASET NOAH_KATAMAK\\ANALISE_ARTIGO 02\\EXPOR_MUNC_UF\\EXPORTACOES_CLASSIFICADAS_COMPLETO.csv\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\noahs\\Área de Trabalho\\DATASET NOAH_KATAMAK\\ANALISE_ARTIGO 02\\OUTPUT_DETALHADO\"\n",
    "EXCEL_OUT = os.path.join(OUTPUT_DIR, \"analise_2018_2025_top5_por_uf_e_ufs_urf.xlsx\")\n",
    "UNIFIED_CSV = os.path.join(OUTPUT_DIR, \"unified_selected_rows_2018_2025.csv\")\n",
    "PLOTS_DIR = os.path.join(OUTPUT_DIR, \"plots\")\n",
    "TOPK = 5\n",
    "MIN_YEAR = 2018\n",
    "MAX_YEAR = 2025\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "def normalize(s):\n",
    "    return \"\" if s is None else s.replace('\\ufeff','').strip()\n",
    "\n",
    "def find_index(header, target):\n",
    "    t = target.strip().lower()\n",
    "    for i,h in enumerate(header):\n",
    "        if normalize(h).lower() == t:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def find_any(header, candidates):\n",
    "    for cand in candidates:\n",
    "        i = find_index(header, cand)\n",
    "        if i is not None:\n",
    "            return i, header[i]\n",
    "    return None, None\n",
    "\n",
    "def parse_num(s):\n",
    "    s = (s or \"\").strip()\n",
    "    if s == \"\":\n",
    "        return 0.0\n",
    "    s = s.replace('.', '').replace(',', '.')\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# leitura cabeçalho e detecção flexível de colunas\n",
    "with open(INPUT_CSV, 'r', encoding='utf-8-sig') as f:\n",
    "    reader = csv.reader(f, delimiter=';')\n",
    "    raw_header = next(reader)\n",
    "    header = [h.strip() for h in raw_header]\n",
    "\n",
    "# mapeamento flexível: listas de variantes aceitáveis\n",
    "candidates = {\n",
    "    'CO_ANO':        ['CO_ANO','ANO','AN0','YEAR'],\n",
    "    'SG_UF_NCM':     ['SG_UF_NCM','SG_UF_MUN','SG_UF','UF','SG_UF_MUN'],\n",
    "    'CO_SH4':        ['CO_SH4','SH4','CO_NCM_SH4','CO_NCM','NCM','SH'],\n",
    "    'VL_FOB':        ['VL_FOB','FOB','VALOR_FOB','VALOR'],\n",
    "    'KG_LIQUIDO':    ['KG_LIQUIDO','KG','PESO_KG','PESO'],\n",
    "    'CO_URF':        ['CO_URF','URF','CO_URF_NCM','URF_CODE']\n",
    "}\n",
    "\n",
    "idx_map = {}\n",
    "missing = []\n",
    "for key, cand_list in candidates.items():\n",
    "    idx, name = find_any(header, cand_list)\n",
    "    if idx is None:\n",
    "        # URF pode faltar; outras são críticas\n",
    "        if key == 'CO_URF':\n",
    "            idx_map[key] = None\n",
    "        else:\n",
    "            missing.append((key, cand_list))\n",
    "    else:\n",
    "        idx_map[key] = idx\n",
    "\n",
    "if missing:\n",
    "    raise SystemExit(f\"Colunas obrigatórias não encontradas: {missing}. Cabeçalho: {header}\")\n",
    "\n",
    "print(\"Colunas detectadas (mapa):\", {k:(v if v is None else header[v]) for k,v in idx_map.items()})\n",
    "\n",
    "# estruturas de agregação\n",
    "sh_by_uf = {}\n",
    "uf_totals = {}\n",
    "urf_by_uf = {}  # só preencherá se CO_URF existir\n",
    "\n",
    "with open(INPUT_CSV, 'r', encoding='utf-8-sig') as f:\n",
    "    reader = csv.reader(f, delimiter=';')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        # proteção contra linhas curtas\n",
    "        if len(row) <= max([i for i in idx_map.values() if i is not None]):\n",
    "            continue\n",
    "        # ano\n",
    "        try:\n",
    "            ano = int(row[idx_map['CO_ANO']].strip())\n",
    "        except:\n",
    "            continue\n",
    "        if ano < MIN_YEAR or ano > MAX_YEAR:\n",
    "            continue\n",
    "        uf = row[idx_map['SG_UF_NCM']].strip()\n",
    "        sh = row[idx_map['CO_SH4']].strip()\n",
    "        fob = parse_num(row[idx_map['VL_FOB']])\n",
    "        kg = parse_num(row[idx_map['KG_LIQUIDO']])\n",
    "        if fob == 0 and kg == 0:\n",
    "            continue\n",
    "\n",
    "        uf_totals.setdefault(uf, {'VL_FOB':0.0, 'KG':0.0})\n",
    "        uf_totals[uf]['VL_FOB'] += fob\n",
    "        uf_totals[uf]['KG'] += kg\n",
    "\n",
    "        sh_by_uf.setdefault(uf, {})\n",
    "        sh_by_uf[uf].setdefault(sh, {'VL_FOB':0.0, 'KG':0.0})\n",
    "        sh_by_uf[uf][sh]['VL_FOB'] += fob\n",
    "        sh_by_uf[uf][sh]['KG'] += kg\n",
    "\n",
    "        # só agrega URF se coluna estiver presente\n",
    "        if idx_map['CO_URF'] is not None:\n",
    "            urf = row[idx_map['CO_URF']].strip()\n",
    "            urf_by_uf.setdefault(uf, {})\n",
    "            urf_by_uf[uf].setdefault(urf, {'VL_FOB':0.0, 'KG':0.0})\n",
    "            urf_by_uf[uf][urf]['VL_FOB'] += fob\n",
    "            urf_by_uf[uf][urf]['KG'] += kg\n",
    "\n",
    "# identificar tops SH4 por UF\n",
    "top5_sh_per_uf = {}\n",
    "for uf, d in sh_by_uf.items():\n",
    "    df = pd.DataFrame([(sh, v['VL_FOB'], v['KG']) for sh,v in d.items()],\n",
    "                      columns=['CO_SH4','VL_FOB','KG'])\n",
    "    top_fob = df.nlargest(TOPK, 'VL_FOB')['CO_SH4'].tolist()\n",
    "    top_kg = df.nlargest(TOPK, 'KG')['CO_SH4'].tolist()\n",
    "    top_union = list(dict.fromkeys(top_fob + top_kg))\n",
    "    top5_sh_per_uf[uf] = {'by_fob': top_fob, 'by_kg': top_kg, 'union': top_union}\n",
    "\n",
    "uf_totals_df = pd.DataFrame([(uf, v['VL_FOB'], v['KG']) for uf,v in uf_totals.items()],\n",
    "                            columns=['SG_UF_NCM','VL_FOB','KG'])\n",
    "top5_ufs_by_fob = uf_totals_df.nlargest(TOPK, 'VL_FOB')['SG_UF_NCM'].tolist()\n",
    "top5_ufs_by_kg = uf_totals_df.nlargest(TOPK, 'KG')['SG_UF_NCM'].tolist()\n",
    "top_ufs_union = list(dict.fromkeys(top5_ufs_by_fob + top5_ufs_by_kg))\n",
    "top2_ufs_by_kg = uf_totals_df.nlargest(2, 'KG')['SG_UF_NCM'].tolist()\n",
    "\n",
    "print(\"Top UFs FOB:\", top5_ufs_by_fob)\n",
    "print(\"Top UFs KG:\", top5_ufs_by_kg)\n",
    "print(\"Top 2 UFs por KG:\", top2_ufs_by_kg)\n",
    "\n",
    "# 2º passe: extrair linhas originais para seleções\n",
    "sheet1_rows = []\n",
    "sheet2_rows = []\n",
    "sheet3_rows = []\n",
    "unified_rows = []\n",
    "\n",
    "with open(INPUT_CSV, 'r', encoding='utf-8-sig') as f:\n",
    "    reader = csv.reader(f, delimiter=';')\n",
    "    raw_header = next(reader)\n",
    "    header = [h.strip() for h in raw_header]\n",
    "    for row in reader:\n",
    "        if len(row) <= max([i for i in idx_map.values() if i is not None]):\n",
    "            continue\n",
    "        try:\n",
    "            ano = int(row[idx_map['CO_ANO']].strip())\n",
    "        except:\n",
    "            continue\n",
    "        if ano < MIN_YEAR or ano > MAX_YEAR:\n",
    "            continue\n",
    "        uf = row[idx_map['SG_UF_NCM']].strip()\n",
    "        sh = row[idx_map['CO_SH4']].strip()\n",
    "        fob = parse_num(row[idx_map['VL_FOB']])\n",
    "        kg = parse_num(row[idx_map['KG_LIQUIDO']])\n",
    "        if fob == 0 and kg == 0:\n",
    "            continue\n",
    "        row_dict = {header[i]: row[i].strip() if i < len(row) else \"\" for i in range(len(header))}\n",
    "        row_dict['CO_SH4'] = sh\n",
    "        row_dict['source_file'] = os.path.basename(INPUT_CSV)\n",
    "\n",
    "        if uf in top5_sh_per_uf and sh in top5_sh_per_uf[uf]['union']:\n",
    "            sheet1_rows.append(row_dict)\n",
    "            unified_rows.append(row_dict)\n",
    "\n",
    "        if uf in top_ufs_union:\n",
    "            topn = set(top5_sh_per_uf.get(uf, {}).get('union', []))\n",
    "            if sh in topn:\n",
    "                sheet2_rows.append(row_dict)\n",
    "                unified_rows.append(row_dict)\n",
    "\n",
    "# sheet3: se não houver URF não gera essa aba\n",
    "if idx_map['CO_URF'] is not None:\n",
    "    for uf in top2_ufs_by_kg:\n",
    "        urf_dict = urf_by_uf.get(uf, {})\n",
    "        urf_df = pd.DataFrame([(urf, v['VL_FOB'], v['KG']) for urf,v in urf_dict.items()],\n",
    "                              columns=['CO_URF','VL_FOB','KG'])\n",
    "        top5_urf_by_kg = urf_df.nlargest(TOPK, 'KG')\n",
    "        top5_urf_by_fob = urf_df.nlargest(TOPK, 'VL_FOB')\n",
    "        for _, r in top5_urf_by_kg.iterrows():\n",
    "            sheet3_rows.append({'SG_UF_NCM': uf, 'CO_URF': r['CO_URF'], 'VL_FOB': r['VL_FOB'], 'KG': r['KG'], 'METRICA':'KG'})\n",
    "        for _, r in top5_urf_by_fob.iterrows():\n",
    "            sheet3_rows.append({'SG_UF_NCM': uf, 'CO_URF': r['CO_URF'], 'VL_FOB': r['VL_FOB'], 'KG': r['KG'], 'METRICA':'FOB'})\n",
    "\n",
    "df_sheet1 = pd.DataFrame(sheet1_rows)\n",
    "df_sheet2 = pd.DataFrame(sheet2_rows)\n",
    "df_sheet3 = pd.DataFrame(sheet3_rows)\n",
    "\n",
    "# salvar unified CSV\n",
    "if unified_rows:\n",
    "    all_keys = list(dict.fromkeys([k for d in unified_rows for k in d.keys()]))\n",
    "    with open(UNIFIED_CSV, 'w', newline='', encoding='utf-8-sig') as fout:\n",
    "        writer = csv.DictWriter(fout, fieldnames=all_keys, delimiter=';')\n",
    "        writer.writeheader()\n",
    "        seen = set()\n",
    "        for d in unified_rows:\n",
    "            key = tuple(d.get(k,\"\") for k in all_keys)\n",
    "            if key in seen:\n",
    "                continue\n",
    "            seen.add(key)\n",
    "            writer.writerow(d)\n",
    "    print(\"CSV unificado salvo em:\", UNIFIED_CSV)\n",
    "else:\n",
    "    print(\"Nenhuma linha selecionada para CSV unificado.\")\n",
    "\n",
    "# salvar Excel com 3 abas (se URF ausente, a aba 3 ficará vazia)\n",
    "with pd.ExcelWriter(EXCEL_OUT, engine='openpyxl') as xw:\n",
    "    (df_sheet1 if not df_sheet1.empty else pd.DataFrame()).to_excel(xw, sheet_name='top5_SH4_por_UF', index=False)\n",
    "    (df_sheet2 if not df_sheet2.empty else pd.DataFrame()).to_excel(xw, sheet_name='top5_SH4_top_UFs', index=False)\n",
    "    (df_sheet3 if not df_sheet3.empty else pd.DataFrame()).to_excel(xw, sheet_name='top5_URF_top2_ufs_kg', index=False)\n",
    "\n",
    "print(\"Excel salvo em:\", EXCEL_OUT)\n",
    "\n",
    "# gerar gráficos para top_ufs_union (visual científico, mais 'juvenil')\n",
    "for uf in top_ufs_union:\n",
    "    d = sh_by_uf.get(uf, {})\n",
    "    if not d:\n",
    "        continue\n",
    "    df = pd.DataFrame([(sh, v['VL_FOB'], v['KG']) for sh,v in d.items()],\n",
    "                      columns=['CO_SH4','VL_FOB','KG'])\n",
    "    top_fob = df.nlargest(TOPK, 'VL_FOB').set_index('CO_SH4')\n",
    "    top_kg = df.nlargest(TOPK, 'KG').set_index('CO_SH4')\n",
    "\n",
    "    for metric, data, suffix in [('VL_FOB', top_fob, 'fob'), ('KG', top_kg, 'kg')]:\n",
    "        if data.empty:\n",
    "            continue\n",
    "        plt.figure(figsize=(9,5))\n",
    "        ax = data[metric].sort_values().plot(kind='barh')\n",
    "        ax.grid(axis='x', linestyle='--', linewidth=0.6, alpha=0.7)\n",
    "        ax.set_xlabel(f\"{metric} (soma {MIN_YEAR}-{MAX_YEAR})\")\n",
    "        ax.set_ylabel(\"SH4\")\n",
    "        ax.set_title(f\"{uf} - Top{TOPK} SH4 por {metric} ({MIN_YEAR}-{MAX_YEAR})\", fontsize=11, weight='bold')\n",
    "        for i, v in enumerate(data[metric].sort_values()):\n",
    "            ax.text(v + v*0.005, i, f\"{v:,.0f}\", va='center', fontsize=9)\n",
    "        plt.tight_layout()\n",
    "        fname = os.path.join(PLOTS_DIR, f\"{uf}_top{TOPK}_{suffix}_{MIN_YEAR}_{MAX_YEAR}.png\")\n",
    "        plt.savefig(fname, dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "print(\"Plots salvos em:\", PLOTS_DIR)\n",
    "print(\"Processo concluído:\", datetime.now())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
